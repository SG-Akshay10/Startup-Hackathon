{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "cbBtErCG1nti"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "stop_words = nlp.Defaults.stop_words\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "slGFNd7M1sc0"
      },
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "pd.set_option('display.max_columns', None)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "tpkYLle7b6DD"
      },
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/Indian Startup.csv')"
      ],
      "metadata": {
        "id": "Qro3rz181s9X"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "gTAzAF_11vNP"
      },
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df1[['Company','Sector','Description','Amount']]"
      ],
      "metadata": {
        "id": "RwQLAVzM1xC7"
      },
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(text):\n",
        "    y=[]\n",
        "    for i in text.split():\n",
        "        y.append(ps.stem(i))\n",
        "    return \" \".join(y)"
      ],
      "metadata": {
        "id": "mordXSIQ1zd7"
      },
      "execution_count": 439,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(df,column):\n",
        "    df[column] = df[column].apply(lambda x:x.split())\n",
        "    df[column] = df[column].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
        "    df[column] = df[column].apply(lambda x:\" \".join(x))\n",
        "    df[column] = df[column].apply(stem)\n",
        "    df[column] = df[column].apply(lambda x: nlp(x.lower()))\n",
        "    df[column] = [' '.join([token.lemma_ for token in doc]) for doc in df[column]]\n",
        "    df[column] = [' '.join([word for word in doc.split() if word not in stop_words]) for doc in df[column]]\n",
        "    df[column].replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)"
      ],
      "metadata": {
        "id": "OExEsG7r119t"
      },
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def desc_similarity(df,column1,column2):\n",
        "  d = {}\n",
        "  d['Company'] = ''\n",
        "  d['Sector'] = \"Web Development\"\n",
        "  d['Description'] = \"SAAS methodology\"\n",
        "  d['Amount'] = 500000\n",
        "\n",
        "  d = pd.DataFrame([d])\n",
        "  df = pd.concat([df_f, d], axis=0, ignore_index=True)\n",
        "\n",
        "  preprocessing(df_f,column1)\n",
        "\n",
        "  df1 = df_f[['Company',column1]]\n",
        "  df2 = df_f[['Company',column2]]\n",
        "\n",
        "  tfidf = TfidfVectorizer(stop_words = \"english\")\n",
        "  tfidf_matrix = tfidf.fit_transform(df1[column1])\n",
        "  tfidf_matrix_df=pd.DataFrame.sparse.from_spmatrix(tfidf_matrix)\n",
        "  df_final=tfidf_matrix_df\n",
        "\n",
        "  x = df_final.iloc[[-1],:] \n",
        "  y = df_final.iloc[:-2,:]\n",
        "\n",
        "  # Calculate the similarity matrix\n",
        "  sim_matrix=cosine_similarity(x,y)\n",
        "  df_sim_matrix = pd.DataFrame(sim_matrix)\n",
        "  sim_scores = list(enumerate(sim_matrix[0]))\n",
        "  sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
        "  s_idx  =  [i[0] for i in sim_scores]\n",
        "  s_scores =  [i[1] for i in sim_scores]\n",
        "\n",
        "  df_similar = pd.DataFrame(columns=[\"Company\", \"Score\"])\n",
        "  df_similar[\"Company\"] = df1.loc[s_idx, \"Company\"]\n",
        "  df_similar[\"Score\"] = s_scores\n",
        "  df_similar=df_similar.loc[(df_similar['Company'] !='')]\n",
        "  df_similar=df_similar.drop_duplicates(subset='Company', keep=\"first\")\n",
        "\n",
        "  \n",
        "  df_similar_N = df_similar.iloc[0:4+1,:]\n",
        "  df_similar_N = pd.merge(df_similar_N, df2, left_on='Company', right_on='Company')\n",
        "  df_similar_N = df_similar_N[df_similar_N['Amount']<=df_similar_N['Amount'].iloc[-1]]\n",
        "  df_similar_N.reset_index(inplace = True)\n",
        "  ca = df_similar_N['Company'].values.tolist() \n",
        "    \n",
        "  # Return the similarity matrix\n",
        "  return ca"
      ],
      "metadata": {
        "id": "-_GbK_e712Yn"
      },
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = desc_similarity(df_f,\"Description\",\"Amount\")\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxYgR2Sa4WI-",
        "outputId": "4f5166b3-754f-4291-ca20-727cf8e56ac6"
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Elixia Tech Solutions', 'ANSR', 'Nexprt', 'DeHaat']\n"
          ]
        }
      ]
    }
  ]
}